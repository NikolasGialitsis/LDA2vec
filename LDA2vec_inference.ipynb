{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LDA2vec_inference.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOJHcQtmvXahlfFgjE0pFj7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a457c4d3e9cc411084439351c3a9874a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7e0f07ef0ac94fad9362128fad8cd886",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a9fa497a49a241bb98b38e6f87475b79",
              "IPY_MODEL_fe9c9e7ea5654d8297741c5431b3f659"
            ]
          }
        },
        "7e0f07ef0ac94fad9362128fad8cd886": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a9fa497a49a241bb98b38e6f87475b79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_52b84a9547094df7a93ad90795326e0e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_16c2c03c43c34a55a904cc7e6cc58aa7"
          }
        },
        "fe9c9e7ea5654d8297741c5431b3f659": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9ea4d7ca017b467fba942bcfd3b73113",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/? [00:00&lt;00:00,  4.79it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_597cda93cf6943028c38fee26412923f"
          }
        },
        "52b84a9547094df7a93ad90795326e0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "16c2c03c43c34a55a904cc7e6cc58aa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9ea4d7ca017b467fba942bcfd3b73113": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "597cda93cf6943028c38fee26412923f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NikolasGialitsis/LDA2vec/blob/master/LDA2vec_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yxg8QP9_4Mka",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "83a77acd-6ffb-4bba-a787-d20b578acdb0"
      },
      "source": [
        "!unzip /content/lda2vec.zip"
      ],
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open /content/lda2vec.zip, /content/lda2vec.zip.zip or /content/lda2vec.zip.ZIP.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-ZOvLFV4PzV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "outputId": "e3ff04ed-4e6c-4fd0-9216-ae8ac4e62786"
      },
      "source": [
        "!pip install spacy\n",
        "!pip install jellyfish\n",
        "!pip install -r /content/lda2vec/requirements.txt \n",
        "!pip install pylda2vec"
      ],
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.6.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.38.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.21.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (46.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.6.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.4.5.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n",
            "Requirement already satisfied: jellyfish in /usr/local/lib/python3.6/dist-packages (0.7.2)\n",
            "Requirement already satisfied: chainer in /usr/local/lib/python3.6/dist-packages (from -r /content/lda2vec/requirements.txt (line 1)) (6.5.0)\n",
            "Collecting cupy\n",
            "  Using cached https://files.pythonhosted.org/packages/3d/fc/110649d12075cd6627113ea5fb6cab1a056a2676113c31c6b3bc7f4086ef/cupy-7.3.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r /content/lda2vec/requirements.txt (line 3)) (1.18.2)\n",
            "Requirement already satisfied: jellyfish in /usr/local/lib/python3.6/dist-packages (from -r /content/lda2vec/requirements.txt (line 4)) (0.7.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from -r /content/lda2vec/requirements.txt (line 5)) (1.0.3)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement en_core_web_md (from -r /content/lda2vec/requirements.txt (line 6)) (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for en_core_web_md (from -r /content/lda2vec/requirements.txt (line 6))\u001b[0m\n",
            "Requirement already satisfied: pylda2vec in /usr/local/lib/python3.6/dist-packages (1.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dSAbNrQzfyI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "outputId": "1ae4a0ee-ec3f-45e0-c691-76742baf0e0e"
      },
      "source": [
        "!python -m spacy download en"
      ],
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (46.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.38.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.21.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.6.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.4.5.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2mâœ” Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGVTEhzz4S-w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2152080d-2bb4-476c-ab55-ad8b51677a4f"
      },
      "source": [
        "%cd /content/lda2vec/\n",
        "import os\n",
        "import os.path\n",
        "import pickle\n",
        "import time\n",
        "import shelve\n",
        "\n",
        "import chainer\n",
        "from chainer import cuda\n",
        "from chainer import serializers\n",
        "import chainer.optimizers as O\n",
        "import numpy as np\n",
        "\n",
        "from lda2vec import utils\n",
        "from lda2vec import prepare_topics, print_top_words_per_topic, topic_coherence\n",
        "from lda2vec import LDA2Vec\n",
        "from lda2vec import preprocess, Corpus\n",
        "#changed Preprocess.py line 'nlp = spacy.load(\"en_core_web_sm\")' to solve error en not found\n",
        "#and removed the import ... as en line \n",
        "\n",
        "import logging\n",
        "logging.basicConfig()\n",
        "import pickle\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import numpy as np\n",
        "from lda2vec import preprocess, Corpus"
      ],
      "execution_count": 307,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/lda2vec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xqsrazu34UVG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b21fec47-ed50-41ee-e562-3f73bd7b1da2"
      },
      "source": [
        "gpu_id = int(os.getenv('CUDA_GPU', 0))\n",
        "cuda.get_device(gpu_id).use()\n",
        "print(\"Using GPU:\" + str(gpu_id))"
      ],
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d96aVZ-4U2K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "826cfbd2-49d7-4932-e861-f63a526dc4e3"
      },
      "source": [
        "import nltk \n",
        "import string\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize "
      ],
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1pv4SDY3e9E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161,
          "referenced_widgets": [
            "a457c4d3e9cc411084439351c3a9874a",
            "7e0f07ef0ac94fad9362128fad8cd886",
            "a9fa497a49a241bb98b38e6f87475b79",
            "fe9c9e7ea5654d8297741c5431b3f659",
            "52b84a9547094df7a93ad90795326e0e",
            "16c2c03c43c34a55a904cc7e6cc58aa7",
            "9ea4d7ca017b467fba942bcfd3b73113",
            "597cda93cf6943028c38fee26412923f"
          ]
        },
        "outputId": "7de9b6b0-13b3-4179-88d4-23b4d7d06660"
      },
      "source": [
        "\n",
        "import json\n",
        "with open('/content/new_document.json') as f:\n",
        "  data = json.loads(f.read())\n",
        "titles = []\n",
        "abstracts = []\n",
        "concats = []\n",
        "for entry in data:\n",
        "  concat = (entry['joint_text']).split('------------------------------')  \n",
        "  title = concat[0]\n",
        "  abstract = concat[1]\n",
        "  print('title:',title)\n",
        "  print('abstract',abstract[:100])\n",
        "  concats.append(concat[0] + ' ' + concat[1])\n",
        "  titles.append(title)\n",
        "  abstracts.append(abstract)\n",
        "\n",
        "stop_words = set(stopwords.words('english')) \n",
        "new_text = []\n",
        "for text in concats.copy():\n",
        "  word_tokens = word_tokenize(text) \n",
        "  #remove stopwords\n",
        "  text = ' '.join([w.lower() for w in word_tokens if not w.lower() in stop_words and len(w) >= 3]) \n",
        "  #remove punctuation\n",
        "  #bioclean    = lambda t: re.sub('[.,?;*!%^&_+():-\\[\\]{}]', '', t.replace('\"', '').replace('/', '').replace('\\\\', '').replace(\"'\", '').strip().lower()).split()\n",
        "\n",
        "  text = ''.join([w for w in text if w not in string.punctuation])\n",
        "  new_text.append(text) \n",
        "\n",
        "max_length = 10000\n",
        "tokens , vocab = preprocess.tokenize(new_text, max_length, merge=False,n_threads=4)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title: [The treatment proposal for the patients with breast diseases in the central epidemic area of 2019 coronavirus disease].\n",
            "\n",
            "abstract \n",
            "Currently, the epidemic of 2019 coronavirus disease (COVID-19) is still ongoing. The characteristic\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a457c4d3e9cc411084439351c3a9874a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6UIt-XMKc6F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = Corpus()\n",
        "# Make a ranked list of rare vs frequent words\n",
        "corpus.update_word_count(tokens)\n",
        "corpus.finalize()\n",
        "# The tokenization uses spaCy indices, and so may have gaps\n",
        "# between indices for words that aren't present in our dataset.\n",
        "# This builds a new compact index\n",
        "compact = corpus.to_compact(tokens)\n",
        "# Remove extremely rare words\n",
        "pruned = corpus.filter_count(compact, min_count=0)\n",
        "# Convert the compactified arrays into bag of words arrays\n",
        "bow = corpus.compact_to_bow(pruned)\n",
        "# Words tend to have power law frequency, so selectively\n",
        "# downsample the most prevalent words\n",
        "clean = corpus.subsample_frequent(pruned)\n",
        "# Now flatten a 2D array of document per row and word position\n",
        "# per column to a 1D array of words. This will also remove skips\n",
        "# and OoV words\n",
        "doc_ids = np.arange(pruned.shape[0])\n",
        "flattened, (doc_ids,) = corpus.compact_to_flat(pruned, doc_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlQ08oF_Bfpk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0823a1b0-8b08-4087-8d75-22a477182127"
      },
      "source": [
        "%cd /content\n",
        "fn_weights = 'weights.pkl'\n",
        "fn_sampler = 'sampler.pkl'\n",
        "fn_factors = 'factors.pkl'\n",
        "weights = pickle.load(open(fn_weights, 'rb'))\n",
        "sampler = pickle.load(open(fn_sampler, 'rb'))\n",
        "factors = pickle.load(open(fn_factors, 'rb'))\n",
        "\n",
        "vocab = pickle.load(open('vocab.pkl', 'rb'))"
      ],
      "execution_count": 312,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QcWMka-FIy4U",
        "colab": {}
      },
      "source": [
        "fn_vocab = 'vocab.pkl'\n",
        "fn_corpus = 'corpus.pkl'\n",
        "fn_flatnd = 'flattened.npy'\n",
        "fn_docids = 'doc_ids.npy'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bl1usxr7C7ND",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "46a0af97-0216-49a8-8516-112c7c8a65b4"
      },
      "source": [
        "# Model Parameters\n",
        "# Number of documents\n",
        "n_docs = doc_ids.max() + 1\n",
        "# Number of unique words in the vocabulary\n",
        "n_vocab = flattened.max() + 1\n",
        "# 'Strength' of the dircihlet prior; 200.0 seems to work well\n",
        "clambda = 200.0\n",
        "# Number of topics to fit\n",
        "n_topics = int(os.getenv('n_topics', 10))\n",
        "batchsize = 16\n",
        "# Power for neg sampling\n",
        "power = float(os.getenv('power', 0.75))\n",
        "# Intialize with pretrained word vectors\n",
        "pretrained = bool(int(os.getenv('pretrained', True)))\n",
        "# Sampling temperature\n",
        "temperature = float(os.getenv('temperature', 1.0))\n",
        "# Number of dimensions in a single word vector\n",
        "n_units = int(os.getenv('n_units', 30))\n",
        "# Get the string representation for every compact key\n",
        "words = corpus.word_list(vocab)[:n_vocab]\n",
        "print(words)\n",
        "# How many tokens are in each document\n",
        "doc_idx, lengths = np.unique(doc_ids, return_counts=True)\n",
        "doc_lengths = np.zeros(doc_ids.max() + 1, dtype='int32')\n",
        "doc_lengths[doc_idx] = lengths\n",
        "\n",
        "# Count all token frequencies\n",
        "tok_idx, freq = np.unique(flattened, return_counts=True)\n",
        "term_frequency = np.zeros(n_vocab, dtype='int32')\n",
        "term_frequency[tok_idx] = freq"
      ],
      "execution_count": 340,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['out_of_vocabulary', 'out_of_vocabulary', '<SKIP>', 'covid19', 'patients', 'coronavirus', 'disease', 'cases', '2019', 'china', 'sarscov2', 'clinical', 'health', 'respiratory', 'infection', 'outbreak', 'severe', 'novel', '2020', 'wuhan', 'epidemic', 'treatment', 'pneumonia', 'virus', 'acute', 'results', 'transmission', 'syndrome', 'control', 'confirmed', 'data', 'february', 'spread', 'risk', 'days', 'study', 'public', 'case', 'symptoms', 'methods', 'reported', 'care', 'infected', 'viral', 'number', 'management', 'may', 'pandemic', 'first', 'measures', 'group', 'countries', 'also', 'prevention', 'early', 'january', 'characteristics', 'caused', 'diagnosis', 'patient', 'findings', 'medical', 'emergency', 'new', '2019ncov', 'world', 'hubei', 'among', 'including', 'time', 'enditag', 'itag', 'hospital', 'december', 'chest', 'two']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vdzjq6FCTYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model = LDA2Vec(n_documents=n_docs, n_document_topics=n_topics,\n",
        "                n_units=n_units, n_vocab=n_vocab, counts=term_frequency,\n",
        "                n_samples=15, power=power, temperature=temperature)\n",
        "vectors = np.load('vectors.npy')\n",
        "model.sampler.W.data[:, :] =  vectors[:n_vocab, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzRdiMdU--9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fn_vocab = 'vocab.pkl'\n",
        "fn_corpus = 'corpus.pkl'\n",
        "\n",
        "vocab = pickle.load(open(fn_vocab, 'rb'))\n",
        "corpus = pickle.load(open(fn_corpus, 'rb'))\n",
        "old_flattened = np.load(fn_flatnd)\n",
        "n_vocab = old_flattened.max() + 1\n",
        "words = corpus.word_list(vocab)[:n_vocab]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzfSQcOHY-uF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VPVoviu3oCS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "b1e483bf-8ff2-4888-e1e3-3e2741c366b8"
      },
      "source": [
        "\n",
        "\n",
        "#model.sampler.W.data[:, :] = new_text[:n_vocab, :]\n",
        "\n",
        "data = prepare_topics(cuda.to_cpu(weights.copy()),\n",
        "                      cuda.to_cpu(factors.copy()),\n",
        "                      cuda.to_cpu(sampler.copy()),\n",
        "                      words)\n",
        "#add new randomized vector for new doc\n",
        "\n",
        "random_doc_topic = np.random.dirichlet(np.ones(10),size=1)\n",
        "first_doc = data['doc_topic_dists'][0]\n",
        "\n",
        "num_docs = data['doc_topic_dists'].shape[0]\n",
        "data['doc_topic_dists'] = np.append(arr=data['doc_topic_dists'],values=random_doc_topic)\n",
        "data['doc_topic_dists'] = data['doc_topic_dists'].reshape(num_docs+1,n_topics)\n",
        "\n",
        "\n",
        "print(data['doc_topic_dists'].shape)\n",
        "print('random_doc = ',random_doc_topic)\n"
      ],
      "execution_count": 343,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(745, 10)\n",
            "random_doc =  [[0.0663702  0.15741455 0.07266566 0.14981045 0.00932821 0.26088289\n",
            "  0.01057492 0.13455583 0.05626844 0.08212885]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ti3ipnO3q_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.to_gpu()\n",
        "optimizer = O.Adam()\n",
        "optimizer.setup(model)\n",
        "clip = chainer.optimizer.GradientClipping(5.0)\n",
        "optimizer.add_hook(clip)\n",
        "j = 0\n",
        "epoch = 0\n",
        "fraction = batchsize * 1.0 / flattened.shape[0]\n",
        "progress = shelve.open('progress.shelve')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-rfVEPN3snK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "936dfeb7-d9ad-4da8-e681-9ed055a2847f"
      },
      "source": [
        "n_epochs = 1500\n",
        "\n",
        "for epoch in range(1):\n",
        "    data = prepare_topics(cuda.to_cpu(weights.copy()),\n",
        "                          cuda.to_cpu(factors.copy()),\n",
        "                          cuda.to_cpu(sampler.copy()),\n",
        "                          words)\n",
        "    #top_words = print_top_words_per_topic(data)\n",
        "    data['doc_lengths'] = doc_lengths\n",
        "    data['term_frequency'] = term_frequency\n",
        "    np.savez('topics.pyldavis', **data)\n",
        "    #print(data)\n",
        "    for d, f in utils.chunks(batchsize, np.array(doc_ids), flattened):\n",
        "        t0 = time.time()\n",
        "        model.cleargrads()\n",
        "        #optimizer.use_cleargrads(use=False)\n",
        "        l = model.fit_partial(d.copy(), f.copy(),update_only_docs=True)\n",
        "        print(l)\n",
        "        print(\"after partial fitting:\", l)\n",
        "        prior = model.prior()\n",
        "        loss = prior * fraction\n",
        "        loss.backward()\n",
        "        optimizer.update()\n",
        "        msg = (\"J:{j:05d} E:{epoch:05d} L:{loss:1.3e} \"\n",
        "               \"P:{prior:1.3e} R:{rate:1.3e}\")\n",
        "        prior.to_cpu()\n",
        "        loss.to_cpu()\n",
        "        t1 = time.time()\n",
        "        dt = t1 - t0\n",
        "        rate = batchsize / dt\n",
        "        logs = dict(loss=float(l), epoch=epoch, j=j,\n",
        "                    prior=float(prior.data), rate=rate)\n",
        "        print(msg.format(**logs))\n",
        "        j += 1"
      ],
      "execution_count": 345,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3356.1287\n",
            "after partial fitting: 3356.1287\n",
            "J:00000 E:00000 L:3.356e+03 P:-2.090e+01 R:2.462e+02\n",
            "20219.592\n",
            "after partial fitting: 20219.592\n",
            "J:00001 E:00000 L:2.022e+04 P:-2.090e+01 R:2.756e+02\n",
            "17371.99\n",
            "after partial fitting: 17371.99\n",
            "J:00002 E:00000 L:1.737e+04 P:-2.090e+01 R:3.497e+02\n",
            "17151.164\n",
            "after partial fitting: 17151.164\n",
            "J:00003 E:00000 L:1.715e+04 P:-2.090e+01 R:3.360e+02\n",
            "11744.21\n",
            "after partial fitting: 11744.21\n",
            "J:00004 E:00000 L:1.174e+04 P:-2.090e+01 R:3.164e+02\n",
            "21842.562\n",
            "after partial fitting: 21842.562\n",
            "J:00005 E:00000 L:2.184e+04 P:-2.090e+01 R:3.395e+02\n",
            "20980.445\n",
            "after partial fitting: 20980.445\n",
            "J:00006 E:00000 L:2.098e+04 P:-2.090e+01 R:3.378e+02\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEvebImu4bJY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "1546812f-2c7c-4a84-abc7-fe74b9d4155f"
      },
      "source": [
        "print('==== MAKE SURE THAT THE OTHER DOCS DONT CHANGE')\n",
        "print(first_doc)\n",
        "print(data['doc_topic_dists'][0])\n",
        "print('\\n==================================')\n",
        "print('==== MAKE SURE THAT THE NEW DOC HAS CHANGED')\n",
        "print(random_doc_topic)\n",
        "print(data['doc_topic_dists'][-1])"
      ],
      "execution_count": 326,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==== MAKE SURE THAT THE OTHER DOCS DONT CHANGE\n",
            "[0.10384709 0.08276632 0.10338711 0.07900679 0.1079841  0.11230687\n",
            " 0.09587169 0.10159854 0.1013382  0.11189319]\n",
            "[0.10384709 0.08276632 0.10338711 0.07900679 0.1079841  0.11230687\n",
            " 0.09587169 0.10159854 0.1013382  0.11189319]\n",
            "\n",
            "==================================\n",
            "==== MAKE SURE THAT THE NEW DOC HAS CHANGED\n",
            "[[0.08702473 0.09879306 0.07320704 0.32777722 0.14274596 0.16095911\n",
            "  0.0242389  0.02595778 0.02104086 0.03825533]]\n",
            "[0.09601615 0.09627663 0.10512727 0.09975246 0.11829065 0.09382185\n",
            " 0.09439588 0.10970131 0.08970814 0.09690975]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1h3k7GV4g_Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "fddfff38-eda0-445d-fc92-5d13018b6e44"
      },
      "source": [
        "t=0\n",
        "print('New Document Composition\\n')\n",
        "for d in data['doc_topic_dists'][-1]:\n",
        "  print('\\t',round(d*100,2),'\\t percent of Topic',t)\n",
        "  t+=1 "
      ],
      "execution_count": 327,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "New Document Composition\n",
            "\n",
            "\t 9.6 \t percent of Topic 0\n",
            "\t 9.63 \t percent of Topic 1\n",
            "\t 10.51 \t percent of Topic 2\n",
            "\t 9.98 \t percent of Topic 3\n",
            "\t 11.83 \t percent of Topic 4\n",
            "\t 9.38 \t percent of Topic 5\n",
            "\t 9.44 \t percent of Topic 6\n",
            "\t 10.97 \t percent of Topic 7\n",
            "\t 8.97 \t percent of Topic 8\n",
            "\t 9.69 \t percent of Topic 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y23qvwNPeyZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pyLDAvis.display(prepared_data)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}